 
GPExp: results analysis of the "hermetic" dataset
 
 
DISCLAMER
 
The information provided below is provided without garantee and should
be considered as an illustrative example of how GPExp results can be exploited
Most of the qualitative analysis is based on experience and cannot be
considered as firm rules. Depending on the dataset, the imposed euristic
boundaries can vary significantly
 
 
DATASET INFORMATION
 
 Hermetic scroll expander, tested at the University of Liege                
                                                                           
Lemort, V, Declaye, S, & Quoilin, S. (2011). Experimental characterization 
of a hermetic scroll expander for use in a micro-scale Rankine cycle.      
Proceedings of the Institution of Mechanical Engineers, Part A, Journal    
of Power and Energy.                                                       
                                                                           
53 Data points                                                             
 
 
MAIN RESULTS
(NB: These results are stored in the out.CV and out.train variables)
 
In training mode (with all the data points):
Mean relative error: 3.8839 %
Coefficient of determination (R square): 95.9363 %
Root mean square error (RMSE): 0.021551
 
In cross-validation:
Mean relative error: 5.0251 %
Coefficient of determination (R square): 93.3629 %
Root mean square error (RMSE): 0.027241
 
These results can be interpreted as follows:
 
The lowest average error that could be reached by a model predicting epsilon_s
as a function of r_p [-], p_{su} [bar] is 3.8839 %
 
When predicting values that are outside of the data, an average error of
5.0251 % can be expected
 
 
DETECTION OF OVERFITTING
 
Overfitting can be detected by comparing the error in training mode and in cross-
validation: in case of overfitting the train error should remain low, while the
CV error should increase significantly
However, there is no firm quantitative rule to detec overfitting. This analysis
therefore provides a warning, which should be checked visually by plotting the function
 
The ratio between the error in CV and training is 1.29
This value relatively low, which tends to indicate that there is no overfitting
  
 
RELEVANCE OF THE SELECTED INPUTS (PERMUTATIONS)
(NB: This result is stored in the out.CV.pmae variable)
 
The dependency of the output with the given inputs is checked by comparing
the mean average error (in cross-validation) of the dataset with a random
dataset (the same with randomly permuted outputs. The reported statistics
in the CV.pmae variable, corresponding to the probability of having a random
dataset performing better in terms of mean average error than the actual
dataset.
A pmae lower than 5 percent indicates that there is a significant correlation between
inputs and outputs
 
Permutations were not used in the present analysis
 
 
OUTLIERS
(NB: These results are stored in the out.outliers vector)
 
The posterior of the Gaussian Process provides the likelihood function,
with its mean and standard deviation. For each data point, the Grubbs
test for outliers can therefore be applied: the error is expressed as the
a multiple of the standard deviation at that particular point. According 
to the normal distribution hypothesis, a multiple higher than 1.96 
indicates a significance level lower than 5 percent
Users should also refer to the error plot to visualize the repartition of 
the error on the normal distribution
 
The data point with the highest probability to be an outlier is:
Data point number 51, with an error 2.3073 times higher than the standard
deviation of the gaussian process function at that particular point
 
The following data points present a significance level lower than 5 percent.
They are therefore likely to be outliers:
Data point number 51: 2.3073
